---
layout: default
title: Computational Text Analyses Bootcamp
nav_order: 2024.05060900
---

<img src="assets/img/TextAnalysisBootcamp.png" alt="Workshop Title Slide" width="100%">

*Background photo image courtesy Ed Robertson via [unsplash](https://unsplash.com/photos/assorted-title-book-lot-eeSdJfLfx1A?utm_content=creditShareLink&utm_medium=referral&utm_source=unsplash)*

# Computational Text Analyses Bootcamp

Do you have a textual analysis project that you are trying to get off the ground? Or are you simply interested in learning more about how to analyze texts with computers? Join us for an intensive - but fun! - bootcamp at the Sherman Centre with opportunities to work on your own documents or a sample corpus if you just want to practice the techniques.  

Through hands-on exercises, we will introduce to the fundamental concepts, processes, and methodological approaches for preparing and analyzing text using computational approaches. We'll show you how to use tools like OpenRefine and Python for text preparation and introduce analytic techniques including named entity recognition (NER), topic modeling, sentiment analysis and stylometry.
Participants are not expected to have any pre-requisite knowledge of text preparation and analysis, but experience with Python is an asset. Participants will be given an opportunity to complete exercises in advance of the workshop to build basic competency. 

**This is an in-person event** and open to all who are able to travel to the Sherman Centre, which is accessibly located on the first floor of Mills Library at McMaster University.

[Register for this workshop](https://libcal.mcmaster.ca/event/3790314){: .btn .btn-outline }

## Workshop Preparation 
In this workshop, we will use the following tools and platforms: 
- [Google Colab](https://colab.google/), which requires a Google account. If this poses a challenge, please reach out to the [Sherman Centre](mailto:scds@mcmaster.ca) for alternative arrangements. 
- [OpenRefine](https://openrefine.org/): [Download](https://openrefine.org/download) and install prior to the first session.
- (optional) [Constellate.org](https://constellate.org/), which is available to all McMaster members, as well as members of other institutions. If you do not have access, please contact the [Sherman Centre](mailto:scds@mcmaster.ca) for alternative arrangements.

<!-- 
All of the materials for this workshop are available at this [shared Google Drive Folder](https://u.mcmaster.ca/dmds-text-2324). If you are unable to access the Google Drive folder, the workshop materials may also be found [here](https://github.com/scds/dmds23-24/tree/main/textanalyses)--these can be uploaded into Google Colab or another Jupyter Notebook instance.
-->

## Facilitator Bios

Devon Mordell is an Educational Developer at The MacPherson Institute for Teaching and Learning. Devon draws on her experience in media art, hobbyist programming and instructional design to teach workshops for the Sherman Centre. Her areas of interest in digital scholarship include data visualization, computational analyses of texts, sonification and critical digital humanities. Her research practice explores the algorithmic culture industry and platform psychogeography.

Jay Brodeur (he/him) is the Director of Digital Scholarship Infrastructure & Services and the Administrative Director of the Sherman Centre for Digital Scholarship. Jay has years of experience working with data in a wide variety of formats and interdisciplinary contexts. A scientist by training with a PhD in Earth and Environmental Sciences, he’s comfortable working and advising on all kinds of data-related activities, ranging from data wrangling and integration to analysis and mapping to research data management. Jay’s also keenly interested in the application of digital approaches to support experiential learning opportunities within and outside of the classroom.

Subhanya Sivajothy (she/her) brings a background of research in data justice, science and technology studies, and environmental humanities. She is currently thinking through participatory data design which allow for visualizations that are empowering for the end user. She also has experience in Research Data Management—particularly data cleaning and curation. Do not hesitate to reach out to her if you would like to talk more about data analysis and visualization as they evolve throughout the research process. Contact Subhanya at sivajos@mcmaster.ca.

## Workshop Materials and Preparation
All files for the bootcamp are available in [this shared Google Drive folder](https://u.mcmaster.ca/cta-bootcamp) [(u.mcmaster.ca/cta-bootcamp)](https://u.mcmaster.ca/cta-bootcamp). Download the contents to your local computer and unzip them, AND copy the contents into your own Google Drive before beginning the exercises.

## Contents

### Day 1
Time: 0930 - 1600
The Jupyter notebook name for each exercise is indicated below.  
[View/download slides](https://github.com/scds/dmds23-24/blob/main/assets/docs/Computational%20Text%20Analysis%20Bootcamp%20-%2020240506.pdf)

|Segment|Time Allotted|Key Topics / Activities|
|:--|:--|:--|
|**Introductory remarks**|20 minutes|Introduction to text preparation and analysis <br> Overview of concepts and methods|
|**Text preparation**|120 minutes|Text prep with OpenRefine <br> Building workflows with Python (`CTA-Bootcamp-2024-python-prep.ipynb`)|
|**Lunch (1200 - 1300)**|60 minutes|**Lunch**|
|**Text Analysis**|180 minutes|Named Entity Recognition [45 mins] (`CTA-Bootcamp-2024-NER.ipynb`)<br> Sentiment Analysis [45 mins] (`CTA-Bootcamp-2024-SA.ipynb`)<br> Topic Modeling [45 mins] (`CTA-Bootcamp-2024-TM.ipynb`)<br> Stylometry [45 mins] (`CTA_Bootcamp_2024_stylometry.ipynb`)|
|**Wrap up**|10 minutes|Recap & thinking about day 2 projects|


### Day 2
Time: 0930 - 1600
[View/download slides](https://github.com/scds/dmds23-24/blob/main/assets/docs/Computational%20Text%20Analysis%20Bootcamp%20-%2020240507.pdf)

|Segment|Time Allotted|Key Topics / Activities|
|:--|:--|:--|
|**Corpora Selection**|30 minutes|Sources and types <br> Key considerations for different source materials and analyses <br> Case studies|
|**Visualization for Dissemination** |75 minutes|Core concepts <br> Visualization types <br> Hands-on exercises|
|**Working Period**|75 minutes|Work on your own data or a pre-selected project|
|**Lunch (1230 - 1330)**|60 minutes|**Lunch**|
|**Working Period**|120 minutes|Continue project work|
|**Share Back, Closing Comments**|30 minutes|Share your work <br> Questions and wrap-up|



<!--
All of the materials for this workshop are available in this [shared Google Folder](https://u.mcmaster.ca/dmds-text-2324). Note that the shared folder includes an additional notebook, which Devon created to demonstrate performing [Named Entity Recognition on a series of documents](https://colab.research.google.com/drive/1BC18oDNM9c9x5VMwzI4VPaapjCbEXYio?usp=sharing). If you are unable to access the Google Drive folder, the workshop materials may also be found [here](https://github.com/scds/dmds23-24/tree/main/textanalyses)--these can be uploaded into Google Colab or another Jupyter Notebook instance.

<embed src="assets/docs/textAnalysisSlides.pdf" style="border:none;" width="100%" height="466px">
[Download as PDF.](assets/docs/textAnalysisSlides.pdf)

-->

## Links and Resources 
Here are a variety of helpful resources to explore and learn more.

### Natural Language Processing

#### Constellate (NLP training and analysis)
[Constellate](https://constellate.org/) is a text analysis learning and analysis platform supported by JSTOR Labs and ITHAKA. McMaster members can access tutorials, digitized materials, and an integrated python notebook environment by registering with their McMaster email address.

Constellate provides:
- A comprehensive set of interactive Jupyter Notebook-based tutorials for text analysis, shared via [GitHub](https://github.com/ithaka/constellate-notebooks) under a CC-BY license.
- Analytical access to content from 35+ million articles, books, and newspapers from JSTOR, Portico, Chronicling America, etc.
- A computational platform to develop notebooks and collect, create, analyze, and store data (to members of McMaster and other subscribing institutions).
- Access to advanced support (to members of McMaster and other subscribing institutions).

To access the features of the pedagogy package (McMaster members): 
1. Sign up for an account using your McMaster email.
	- If on campus, navigate to [https://constellate.org/register](https://constellate.org/register).
	- If off-campus, log in via the [Library’s off-campus access service](https://u.mcmaster.ca/constellate-signup). 
1. Follow the instructions to verify your account
1. Log in via [https://constellate.org/login](https://constellate.org/login). 
	- If you are off campus and aren’t recognized as a McMaster member, log out and back in via [McMaster Library off-campus access](https://u.mcmaster.ca/constellate-login). 

#### Other tutorials and resources
- Check out Devon Mordell's two excellent text prep and analysis modules shared through the SCDS: [Pre-Processing Digitized Texts](https://scds.github.io/text-analysis-1/) and [Named Entity Recognition](https://scds.github.io/text-analysis-2/).
- [How to Clean Text for Machine Learning with Python](https://machinelearningmastery.com/clean-text-machine-learning-python/). An excellent step-by-step walkthrough of the fundamentals of text prep with Python.
- [Python Regex (Regular Expressions) for Data Scientists](https://www.dataquest.io/blog/regular-expressions-data-scientists/)
- [Cleaning OCR’d text with Regular Expressions](https://programminghistorian.org/en/lessons/cleaning-ocrd-text-with-regular-expressions) by Laura Turner O'Hara for The Programming Historian.
- [Natural Language Processing With Python's NLTK Package](https://realpython.com/nltk-nlp-python/#getting-text-to-analyze): An excellent end-to-end tutorial using the nltk package
- [Natural Language Processing with Python: Introduction](https://sanjayasubedi.com.np/nlp/nlp-intro/). This is an excellent step-by-step introduction to basic pre-processing steps (though no clustering or error find/replace)
- [Using Binder to connect GitHub repositories to Jupyter Notebooks](https://github.com/alan-turing-institute/the-turing-way/blob/master/workshops/boost-research-reproducibility-binder/workshop-presentations/zero-to-binder-python.md#1-creating-a-repo-to-binderize)

### OpenRefine
- [Library Carpentry lesson on OpenRefine](https://librarycarpentry.github.io/lc-open-refine/setup.html)
- [University of Toronto Libraries OpenRefine tutorials](https://mdl.library.utoronto.ca/tools/openrefine)
- [OpenRefine Manual on Regular Expressions](https://docs.openrefine.org/manual/expressions#regular-expressions)
- [Using regular expressions in OpenRefine](https://gist.github.com/pmgreen/6e133c5dcde65762d29c): Tutorial by Peter Green, includes non-Latin script.

### Regular Expressions
- Regular expression testers
	- [https://www.regular-expressions.info/](https://www.regular-expressions.info/)
	- [https://regex101.com/](https://regex101.com/)
	- [Regexr](https://regexr.com/): Interactive regular expression (regex) coder and explainer

### Python

#### Python Integrated Development Environments
- There are many, many different Python IDEs. Find which one is [best for you](https://realpython.com/python-ides-code-editors-guide/). Jay is partial to [Pyzo](https://pyzo.org/).

#### Python packages for text prep and Natural Langauge Processing
- [PyTesseract](https://stackabuse.com/pytesseract-simple-python-optical-character-recognition): Simple Python Optical Character Recognition
- [spaCy](https://spacy.io/usage/spacy-101/) NLP library and documentation
- [NLTK](https://www.nltk.org/) NLP library and docmentation
- [natas](https://pypi.org/project/natas/): Library for  processing historical English corpora, especially for studying neologisms
- [Python phonetics package](https://pypi.org/project/phonetics/#usage), which includes methods for matching and clustering words by phonetic similarity
- [pyspellchecker](https://pyspellchecker.readthedocs.io/en/latest/): A simple Python-based spell checking algorithm
- [BookNLP](https://github.com/booknlp/booknlp): A natural language processing pipeline that scales to books and other long documents (in English).
